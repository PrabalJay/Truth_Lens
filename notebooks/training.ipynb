{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vM8zxORsZRYC",
        "outputId": "8245dba3-0e77-4dc0-ba4f-3fd5b9a15295"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üî¥ RESETTING ENVIRONMENT...\n",
            "\u001b[33mWARNING: Skipping facenet-pytorch as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: No matching packages\u001b[0m\u001b[33m\n",
            "\u001b[0m\n",
            "============================================================\n",
            "‚úÖ RESET COMPLETE!\n",
            "üî¥ NOW: Click Runtime ‚Üí Restart session\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "print(\"üî¥ RESETTING ENVIRONMENT...\")\n",
        "\n",
        "!pip uninstall -y torch torchvision torchaudio numpy pandas scikit-learn opencv-python pillow facenet-pytorch albumentations matplotlib seaborn tqdm -q\n",
        "\n",
        "!pip cache purge -q\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"‚úÖ RESET COMPLETE!\")\n",
        "print(\"üî¥ NOW: Click Runtime ‚Üí Restart session\")\n",
        "print(\"=\"*60)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "OohlQiS2Zwll",
        "outputId": "0e7a9caf-bb59-4b7d-9074-e205e8d6ab72"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üì¶ Installing packages that WORK in Colab...\n",
            "Collecting numpy==1.26.4\n",
            "  Downloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.0 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m18.0/18.0 MB\u001b[0m \u001b[31m91.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "rasterio 1.5.0 requires numpy>=2, but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-python 4.13.0.92 requires numpy>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "tobler 0.13.0 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "shap 0.50.0 requires numpy>=2, but you have numpy 1.26.4 which is incompatible.\n",
            "pytensor 2.37.0 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "jaxlib 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-contrib-python 4.13.0.92 requires numpy>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "jax 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-python-headless 4.13.0.92 requires numpy>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.26.4\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "id": "17467457ce8841fbbb33458cb4e7da4a",
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://download.pytorch.org/whl/cpu\n",
            "Collecting torch==2.5.1\n",
            "  Downloading https://download.pytorch.org/whl/cpu/torch-2.5.1%2Bcpu-cp312-cp312-linux_x86_64.whl (174.6 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m174.6/174.6 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchvision==0.20.1\n",
            "  Downloading https://download.pytorch.org/whl/cpu/torchvision-0.20.1%2Bcpu-cp312-cp312-linux_x86_64.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m43.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchaudio==2.5.1\n",
            "  Downloading https://download.pytorch.org/whl/cpu/torchaudio-2.5.1%2Bcpu-cp312-cp312-linux_x86_64.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m92.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch==2.5.1) (3.20.3)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from torch==2.5.1) (4.15.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch==2.5.1) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch==2.5.1) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch==2.5.1) (2025.3.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch==2.5.1) (75.2.0)\n",
            "Collecting sympy==1.13.1 (from torch==2.5.1)\n",
            "  Downloading sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision==0.20.1) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision==0.20.1) (11.3.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy==1.13.1->torch==2.5.1) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch==2.5.1) (3.0.3)\n",
            "Downloading sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m80.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: sympy, torch, torchvision, torchaudio\n",
            "  Attempting uninstall: sympy\n",
            "    Found existing installation: sympy 1.14.0\n",
            "    Uninstalling sympy-1.14.0:\n",
            "      Successfully uninstalled sympy-1.14.0\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.9.0+cu128\n",
            "    Uninstalling torch-2.9.0+cu128:\n",
            "      Successfully uninstalled torch-2.9.0+cu128\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.24.0+cu128\n",
            "    Uninstalling torchvision-0.24.0+cu128:\n",
            "      Successfully uninstalled torchvision-0.24.0+cu128\n",
            "  Attempting uninstall: torchaudio\n",
            "    Found existing installation: torchaudio 2.9.0+cu128\n",
            "    Uninstalling torchaudio-2.9.0+cu128:\n",
            "      Successfully uninstalled torchaudio-2.9.0+cu128\n",
            "Successfully installed sympy-1.13.1 torch-2.5.1+cpu torchaudio-2.5.1+cpu torchvision-0.20.1+cpu\n",
            "Collecting pandas==2.2.3\n",
            "  Downloading pandas-2.2.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (89 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m89.9/89.9 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas==2.2.3) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas==2.2.3) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas==2.2.3) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas==2.2.3) (2025.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas==2.2.3) (1.17.0)\n",
            "Downloading pandas-2.2.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.7 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m12.7/12.7 MB\u001b[0m \u001b[31m99.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pandas\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 2.2.2\n",
            "    Uninstalling pandas-2.2.2:\n",
            "      Successfully uninstalled pandas-2.2.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\n",
            "tobler 0.13.0 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "shap 0.50.0 requires numpy>=2, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed pandas-2.2.3\n",
            "Requirement already satisfied: scikit-learn==1.6.1 in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.12/dist-packages (from scikit-learn==1.6.1) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn==1.6.1) (1.16.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn==1.6.1) (1.5.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn==1.6.1) (3.6.0)\n",
            "Collecting opencv-python==4.10.0.84\n",
            "  Downloading opencv_python-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.12/dist-packages (from opencv-python==4.10.0.84) (1.26.4)\n",
            "Downloading opencv_python-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (62.5 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m62.5/62.5 MB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: opencv-python\n",
            "  Attempting uninstall: opencv-python\n",
            "    Found existing installation: opencv-python 4.13.0.92\n",
            "    Uninstalling opencv-python-4.13.0.92:\n",
            "      Successfully uninstalled opencv-python-4.13.0.92\n",
            "Successfully installed opencv-python-4.10.0.84\n",
            "Collecting Pillow==11.0.0\n",
            "  Downloading pillow-11.0.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (9.1 kB)\n",
            "Downloading pillow-11.0.0-cp312-cp312-manylinux_2_28_x86_64.whl (4.4 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m53.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: Pillow\n",
            "  Attempting uninstall: Pillow\n",
            "    Found existing installation: pillow 11.3.0\n",
            "    Uninstalling pillow-11.3.0:\n",
            "      Successfully uninstalled pillow-11.3.0\n",
            "Successfully installed Pillow-11.0.0\n",
            "Requirement already satisfied: matplotlib==3.10.0 in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib==3.10.0) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib==3.10.0) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib==3.10.0) (4.61.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib==3.10.0) (1.4.9)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.12/dist-packages (from matplotlib==3.10.0) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib==3.10.0) (26.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib==3.10.0) (11.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib==3.10.0) (3.3.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib==3.10.0) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib==3.10.0) (1.17.0)\n",
            "Requirement already satisfied: seaborn==0.13.2 in /usr/local/lib/python3.12/dist-packages (0.13.2)\n",
            "Requirement already satisfied: numpy!=1.24.0,>=1.20 in /usr/local/lib/python3.12/dist-packages (from seaborn==0.13.2) (1.26.4)\n",
            "Requirement already satisfied: pandas>=1.2 in /usr/local/lib/python3.12/dist-packages (from seaborn==0.13.2) (2.2.3)\n",
            "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in /usr/local/lib/python3.12/dist-packages (from seaborn==0.13.2) (3.10.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn==0.13.2) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn==0.13.2) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn==0.13.2) (4.61.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn==0.13.2) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn==0.13.2) (26.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn==0.13.2) (11.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn==0.13.2) (3.3.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn==0.13.2) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.2->seaborn==0.13.2) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.2->seaborn==0.13.2) (2025.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn==0.13.2) (1.17.0)\n",
            "Collecting tqdm==4.67.1\n",
            "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m57.7/57.7 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tqdm\n",
            "  Attempting uninstall: tqdm\n",
            "    Found existing installation: tqdm 4.67.3\n",
            "    Uninstalling tqdm-4.67.3:\n",
            "      Successfully uninstalled tqdm-4.67.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tobler 0.13.0 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "shap 0.50.0 requires numpy>=2, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed tqdm-4.67.1\n",
            "Collecting albumentations==1.4.24\n",
            "  Downloading albumentations-1.4.24-py3-none-any.whl.metadata (37 kB)\n",
            "Requirement already satisfied: numpy>=1.24.4 in /usr/local/lib/python3.12/dist-packages (from albumentations==1.4.24) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.10.0 in /usr/local/lib/python3.12/dist-packages (from albumentations==1.4.24) (1.16.3)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.12/dist-packages (from albumentations==1.4.24) (6.0.3)\n",
            "Requirement already satisfied: pydantic>=2.9.2 in /usr/local/lib/python3.12/dist-packages (from albumentations==1.4.24) (2.12.3)\n",
            "Collecting albucore==0.0.23 (from albumentations==1.4.24)\n",
            "  Downloading albucore-0.0.23-py3-none-any.whl.metadata (5.3 kB)\n",
            "Requirement already satisfied: opencv-python-headless>=4.9.0.80 in /usr/local/lib/python3.12/dist-packages (from albumentations==1.4.24) (4.13.0.92)\n",
            "Requirement already satisfied: stringzilla>=3.10.4 in /usr/local/lib/python3.12/dist-packages (from albucore==0.0.23->albumentations==1.4.24) (4.6.0)\n",
            "Requirement already satisfied: simsimd>=5.9.2 in /usr/local/lib/python3.12/dist-packages (from albucore==0.0.23->albumentations==1.4.24) (6.5.12)\n",
            "Collecting numpy>=1.24.4 (from albumentations==1.4.24)\n",
            "  Downloading numpy-2.4.2-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.9.2->albumentations==1.4.24) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.9.2->albumentations==1.4.24) (2.41.4)\n",
            "Requirement already satisfied: typing-extensions>=4.14.1 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.9.2->albumentations==1.4.24) (4.15.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.9.2->albumentations==1.4.24) (0.4.2)\n",
            "Downloading albumentations-1.4.24-py3-none-any.whl (274 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m274.9/274.9 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading albucore-0.0.23-py3-none-any.whl (14 kB)\n",
            "Downloading numpy-2.4.2-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.6 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m16.6/16.6 MB\u001b[0m \u001b[31m108.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy, albucore, albumentations\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.26.4\n",
            "    Uninstalling numpy-1.26.4:\n",
            "      Successfully uninstalled numpy-1.26.4\n",
            "  Attempting uninstall: albucore\n",
            "    Found existing installation: albucore 0.0.24\n",
            "    Uninstalling albucore-0.0.24:\n",
            "      Successfully uninstalled albucore-0.0.24\n",
            "  Attempting uninstall: albumentations\n",
            "    Found existing installation: albumentations 2.0.8\n",
            "    Uninstalling albumentations-2.0.8:\n",
            "      Successfully uninstalled albumentations-2.0.8\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\n",
            "tensorflow 2.19.0 requires numpy<2.2.0,>=1.26.0, but you have numpy 2.4.2 which is incompatible.\n",
            "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.4.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed albucore-0.0.23 albumentations-1.4.24 numpy-2.4.2\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "id": "85011fe50dd74d4bb78d987466103388",
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting facenet-pytorch==2.6.0\n",
            "  Downloading facenet_pytorch-2.6.0-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting numpy<2.0.0,>=1.24.0 (from facenet-pytorch==2.6.0)\n",
            "  Using cached numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "Collecting Pillow<10.3.0,>=10.2.0 (from facenet-pytorch==2.6.0)\n",
            "  Downloading pillow-10.2.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from facenet-pytorch==2.6.0) (2.32.4)\n",
            "Collecting torch<2.3.0,>=2.2.0 (from facenet-pytorch==2.6.0)\n",
            "  Downloading torch-2.2.2-cp312-cp312-manylinux1_x86_64.whl.metadata (25 kB)\n",
            "Collecting torchvision<0.18.0,>=0.17.0 (from facenet-pytorch==2.6.0)\n",
            "  Downloading torchvision-0.17.2-cp312-cp312-manylinux1_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from facenet-pytorch==2.6.0) (4.67.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.0.0->facenet-pytorch==2.6.0) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.0.0->facenet-pytorch==2.6.0) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.0.0->facenet-pytorch==2.6.0) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.0.0->facenet-pytorch==2.6.0) (2026.1.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch==2.6.0) (3.20.3)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch==2.6.0) (4.15.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch==2.6.0) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch==2.6.0) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch==2.6.0) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch==2.6.0) (2025.3.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch<2.3.0,>=2.2.0->facenet-pytorch==2.6.0)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch<2.3.0,>=2.2.0->facenet-pytorch==2.6.0)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch<2.3.0,>=2.2.0->facenet-pytorch==2.6.0)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch<2.3.0,>=2.2.0->facenet-pytorch==2.6.0)\n",
            "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch<2.3.0,>=2.2.0->facenet-pytorch==2.6.0)\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch<2.3.0,>=2.2.0->facenet-pytorch==2.6.0)\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch<2.3.0,>=2.2.0->facenet-pytorch==2.6.0)\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch<2.3.0,>=2.2.0->facenet-pytorch==2.6.0)\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch<2.3.0,>=2.2.0->facenet-pytorch==2.6.0)\n",
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.19.3 (from torch<2.3.0,>=2.2.0->facenet-pytorch==2.6.0)\n",
            "  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch<2.3.0,>=2.2.0->facenet-pytorch==2.6.0)\n",
            "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.12/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch<2.3.0,>=2.2.0->facenet-pytorch==2.6.0) (12.8.93)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch<2.3.0,>=2.2.0->facenet-pytorch==2.6.0) (3.0.3)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->torch<2.3.0,>=2.2.0->facenet-pytorch==2.6.0) (1.3.0)\n",
            "Downloading facenet_pytorch-2.6.0-py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m37.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.0 MB)\n",
            "Downloading pillow-10.2.0-cp312-cp312-manylinux_2_28_x86_64.whl (4.5 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m75.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torch-2.2.2-cp312-cp312-manylinux1_x86_64.whl (755.5 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m755.5/755.5 MB\u001b[0m \u001b[31m845.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m72.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m62.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m55.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m615.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchvision-0.17.2-cp312-cp312-manylinux1_x86_64.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m91.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: Pillow, nvidia-nvtx-cu12, nvidia-nccl-cu12, nvidia-cusparse-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, nvidia-cusolver-cu12, nvidia-cudnn-cu12, torch, torchvision, facenet-pytorch\n",
            "  Attempting uninstall: Pillow\n",
            "    Found existing installation: pillow 11.0.0\n",
            "    Uninstalling pillow-11.0.0:\n",
            "      Successfully uninstalled pillow-11.0.0\n",
            "  Attempting uninstall: nvidia-nvtx-cu12\n",
            "    Found existing installation: nvidia-nvtx-cu12 12.8.90\n",
            "    Uninstalling nvidia-nvtx-cu12-12.8.90:\n",
            "      Successfully uninstalled nvidia-nvtx-cu12-12.8.90\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.27.5\n",
            "    Uninstalling nvidia-nccl-cu12-2.27.5:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.27.5\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.8.93\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.8.93:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.8.93\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.9.90\n",
            "    Uninstalling nvidia-curand-cu12-10.3.9.90:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.9.90\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.3.3.83\n",
            "    Uninstalling nvidia-cufft-cu12-11.3.3.83:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.3.3.83\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.8.90\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.8.90:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.8.90\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.8.93\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.8.93:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.8.93\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.8.90\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.8.90:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.8.90\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.8.4.1\n",
            "    Uninstalling nvidia-cublas-cu12-12.8.4.1:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.8.4.1\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.4.2\n",
            "    Uninstalling numpy-2.4.2:\n",
            "      Successfully uninstalled numpy-2.4.2\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.7.3.90\n",
            "    Uninstalling nvidia-cusolver-cu12-11.7.3.90:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.7.3.90\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.10.2.21\n",
            "    Uninstalling nvidia-cudnn-cu12-9.10.2.21:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.10.2.21\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.5.1+cpu\n",
            "    Uninstalling torch-2.5.1+cpu:\n",
            "      Successfully uninstalled torch-2.5.1+cpu\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.20.1+cpu\n",
            "    Uninstalling torchvision-0.20.1+cpu:\n",
            "      Successfully uninstalled torchvision-0.20.1+cpu\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.5.1+cpu requires torch==2.5.1, but you have torch 2.2.2 which is incompatible.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\n",
            "rasterio 1.5.0 requires numpy>=2, but you have numpy 1.26.4 which is incompatible.\n",
            "tobler 0.13.0 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "shap 0.50.0 requires numpy>=2, but you have numpy 1.26.4 which is incompatible.\n",
            "pytensor 2.37.0 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "jaxlib 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-contrib-python 4.13.0.92 requires numpy>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "jax 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-python-headless 4.13.0.92 requires numpy>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed Pillow-10.2.0 facenet-pytorch-2.6.0 numpy-1.26.4 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvtx-cu12-12.1.105 torch-2.2.2 torchvision-0.17.2\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "id": "0a225fa404d0435ea0521b9c9800fe05",
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "‚úÖ INSTALLATION COMPLETE!\n",
            "üî¥ NOW: Click Runtime ‚Üí Restart session\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "print(\"üì¶ Installing packages that WORK in Colab...\")\n",
        "\n",
        "!pip install numpy==1.26.4\n",
        "\n",
        "!pip install torch==2.5.1 torchvision==0.20.1 torchaudio==2.5.1 --index-url https://download.pytorch.org/whl/cpu\n",
        "\n",
        "!pip install pandas==2.2.3\n",
        "!pip install scikit-learn==1.6.1\n",
        "!pip install opencv-python==4.10.0.84\n",
        "!pip install Pillow==11.0.0\n",
        "!pip install matplotlib==3.10.0\n",
        "!pip install seaborn==0.13.2\n",
        "!pip install tqdm==4.67.1\n",
        "!pip install albumentations==1.4.24\n",
        "!pip install facenet-pytorch==2.6.0\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"‚úÖ INSTALLATION COMPLETE!\")\n",
        "print(\"üî¥ NOW: Click Runtime ‚Üí Restart session\")\n",
        "print(\"=\"*60)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XO3cSsiGexJq",
        "outputId": "af231296-bb1e-4a6d-de9c-10363cd1e91b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "üîç VERIFYING IMPORTS...\n",
            "============================================================\n",
            "\n",
            "‚úÖ ALL IMPORTS SUCCESSFUL!\n",
            "\n",
            "üìä VERSION SUMMARY:\n",
            "--------------------------------------------------\n",
            "PyTorch: 2.2.2+cu121\n",
            "Torchvision: 0.17.2+cu121\n",
            "NumPy: 1.26.4\n",
            "Pandas: 2.2.3\n",
            "OpenCV: 4.10.0\n",
            "Pillow: 10.2.0\n",
            "scikit-learn: 1.6.1\n",
            "Albumentations: 1.4.24\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/albumentations/__init__.py:24: UserWarning: A new version of Albumentations is available: 2.0.8 (you have 1.4.24). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
            "  check_for_updates()\n"
          ]
        }
      ],
      "source": [
        "print(\"=\"*60)\n",
        "print(\"üîç VERIFYING IMPORTS...\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import cv2\n",
        "import PIL\n",
        "import sklearn\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "from facenet_pytorch import MTCNN\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"\\n‚úÖ ALL IMPORTS SUCCESSFUL!\\n\")\n",
        "print(\"üìä VERSION SUMMARY:\")\n",
        "print(\"-\" * 50)\n",
        "print(f\"PyTorch: {torch.__version__}\")\n",
        "print(f\"Torchvision: {torchvision.__version__}\")\n",
        "print(f\"NumPy: {np.__version__}\")\n",
        "print(f\"Pandas: {pd.__version__}\")\n",
        "print(f\"OpenCV: {cv2.__version__}\")\n",
        "print(f\"Pillow: {PIL.__version__}\")\n",
        "print(f\"scikit-learn: {sklearn.__version__}\")\n",
        "print(f\"Albumentations: {A.__version__}\")\n",
        "print(\"-\" * 50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q77A8zoKfAMY",
        "outputId": "6acb02bc-71b9-4e1f-9530-80dbdda2ef11"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üß™ Testing MTCNN face detector...\n",
            "‚úÖ MTCNN working! Detection result: False\n"
          ]
        }
      ],
      "source": [
        "print(\"üß™ Testing MTCNN face detector...\")\n",
        "\n",
        "mtcnn = MTCNN(keep_all=True)\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "dummy_image = np.random.randint(0, 255, (480, 640, 3), dtype=np.uint8)\n",
        "\n",
        "boxes, probs = mtcnn.detect(dummy_image)\n",
        "print(f\"‚úÖ MTCNN working! Detection result: {boxes is not None}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xjvZ2GEtfbHl",
        "outputId": "77f816eb-6dd3-4433-8c3c-4094bc1302e7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "‚úÖ Google Drive mounted!\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os\n",
        "os.makedirs('/content/drive/MyDrive/TruthLens/models', exist_ok=True)\n",
        "os.makedirs('/content/TruthLens', exist_ok=True)\n",
        "\n",
        "print(\"‚úÖ Google Drive mounted!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "id": "AJj4nPlOfrLd",
        "outputId": "91230138-e27c-4974-8392-2250e1d0acab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üì§ Upload your kaggle.json file\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-1f92fd2a-3080-4a97-a7fc-adee168acf9e\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-1f92fd2a-3080-4a97-a7fc-adee168acf9e\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving kaggle.json to kaggle.json\n",
            "‚úÖ Kaggle configured!\n"
          ]
        }
      ],
      "source": [
        "!pip install -q kaggle\n",
        "\n",
        "from google.colab import files\n",
        "print(\"üì§ Upload your kaggle.json file\")\n",
        "uploaded = files.upload()\n",
        "\n",
        "!mkdir -p ~/.kaggle\n",
        "!mv kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "print(\"‚úÖ Kaggle configured!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BCMp6puwjDaY",
        "outputId": "f12a3502-64c5-4da7-8756-329c72ebeabb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/xhlulu/140k-real-and-fake-faces\n",
            "License(s): other\n",
            "Downloading 140k-real-and-fake-faces.zip to /content\n",
            "100% 3.75G/3.75G [00:54<00:00, 257MB/s]\n",
            "100% 3.75G/3.75G [00:54<00:00, 74.1MB/s]\n",
            "‚úÖ Dataset downloaded!\n",
            "Found 50000 real images\n",
            "Found 50000 fake images\n"
          ]
        }
      ],
      "source": [
        "!kaggle datasets download -d xhlulu/140k-real-and-fake-faces\n",
        "!unzip -q 140k-real-and-fake-faces.zip -d /content/dataset/\n",
        "\n",
        "print(\"‚úÖ Dataset downloaded!\")\n",
        "\n",
        "import glob\n",
        "real = glob.glob('/content/dataset/real_vs_fake/real-vs-fake/train/real/*.jpg')\n",
        "fake = glob.glob('/content/dataset/real_vs_fake/real-vs-fake/train/fake/*.jpg')\n",
        "print(f\"Found {len(real)} real images\")\n",
        "print(f\"Found {len(fake)} fake images\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OdjgFnUYjxex",
        "outputId": "d03bea21-158a-4cf4-d18a-70e19ffafd47"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ SpatialAttention defined!\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import models\n",
        "\n",
        "class SpatialAttention(nn.Module):\n",
        "    def __init__(self, in_channels):\n",
        "        super().__init__()\n",
        "        self.query = nn.Conv2d(in_channels, in_channels//8, kernel_size=1)\n",
        "        self.key = nn.Conv2d(in_channels, in_channels//8, kernel_size=1)\n",
        "        self.value = nn.Conv2d(in_channels, in_channels, kernel_size=1)\n",
        "        self.gamma = nn.Parameter(torch.zeros(1))\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch, channels, height, width = x.size()\n",
        "\n",
        "        query = self.query(x).view(batch, -1, height * width).permute(0, 2, 1)\n",
        "        key = self.key(x).view(batch, -1, height * width)\n",
        "        energy = torch.bmm(query, key)\n",
        "        attention = F.softmax(energy, dim=-1)\n",
        "\n",
        "        value = self.value(x).view(batch, -1, height * width)\n",
        "        out = torch.bmm(value, attention.permute(0, 2, 1))\n",
        "        out = out.view(batch, channels, height, width)\n",
        "\n",
        "        return self.gamma * out + x\n",
        "\n",
        "print(\"‚úÖ SpatialAttention defined!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QNYO3DsPj4Pl",
        "outputId": "34b456f4-f9b2-4998-e0c3-5d587863dd77"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ DeepfakeModel defined!\n"
          ]
        }
      ],
      "source": [
        "class DeepfakeModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.backbone = models.efficientnet_b3(pretrained=True)\n",
        "        self.backbone.classifier = nn.Identity()\n",
        "\n",
        "        self.attention = SpatialAttention(1536)\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(1536, 1024),\n",
        "            nn.BatchNorm1d(1024),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(1024, 512),\n",
        "            nn.BatchNorm1d(512),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(512, 2)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        features = self.backbone(x)\n",
        "        features = features.unsqueeze(-1).unsqueeze(-1)\n",
        "        features = self.attention(features)\n",
        "        features = features.squeeze(-1).squeeze(-1)\n",
        "        output = self.classifier(features)\n",
        "        return output\n",
        "\n",
        "print(\"‚úÖ DeepfakeModel defined!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W7OlKN9vkCPU",
        "outputId": "d2aabc62-c747-4e8a-8c81-70da0465553d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ DeepfakeDataset defined!\n"
          ]
        }
      ],
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "import cv2\n",
        "import numpy as np\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "from facenet_pytorch import MTCNN\n",
        "\n",
        "class DeepfakeDataset(Dataset):\n",
        "    def __init__(self, df, transform=None, is_train=True):\n",
        "        self.df = df\n",
        "        self.transform = transform\n",
        "        self.is_train = is_train\n",
        "\n",
        "        self.face_detector = MTCNN(\n",
        "            keep_all=True,\n",
        "            device='cuda' if torch.cuda.is_available() else 'cpu',\n",
        "            select_largest=True,\n",
        "            post_process=False,\n",
        "            min_face_size=40\n",
        "        )\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def extract_face(self, image):\n",
        "        try:\n",
        "            boxes, _ = self.face_detector.detect(image)\n",
        "            if boxes is not None:\n",
        "                areas = (boxes[:, 2] - boxes[:, 0]) * (boxes[:, 3] - boxes[:, 1])\n",
        "                largest_idx = np.argmax(areas)\n",
        "                box = boxes[largest_idx]\n",
        "\n",
        "                x1, y1, x2, y2 = box.astype(int)\n",
        "\n",
        "                margin = int((x2 - x1) * 0.2)\n",
        "                x1 = max(0, x1 - margin)\n",
        "                y1 = max(0, y1 - margin)\n",
        "                x2 = min(image.shape[1], x2 + margin)\n",
        "                y2 = min(image.shape[0], y2 + margin)\n",
        "\n",
        "                face = image[y1:y2, x1:x2]\n",
        "                return cv2.resize(face, (224, 224))\n",
        "        except Exception as e:\n",
        "            pass\n",
        "\n",
        "        return cv2.resize(image, (224, 224))\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "\n",
        "        image = cv2.imread(row['path'])\n",
        "        if image is None:\n",
        "            return self.__getitem__((idx + 1) % len(self.df))\n",
        "\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        image = self.extract_face(image)\n",
        "\n",
        "        if self.transform:\n",
        "            augmented = self.transform(image=image)\n",
        "            image = augmented['image']\n",
        "        else:\n",
        "            transform = A.Compose([\n",
        "                A.Resize(224, 224),\n",
        "                A.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                          std=[0.229, 0.224, 0.225]),\n",
        "                ToTensorV2()\n",
        "            ])\n",
        "            augmented = transform(image=image)\n",
        "            image = augmented['image']\n",
        "\n",
        "        label = row['label']\n",
        "\n",
        "        return image, label\n",
        "\n",
        "print(\"‚úÖ DeepfakeDataset defined!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ds1cMs2YkVg8",
        "outputId": "1d61debc-3506-464c-83c5-3d95b81ec30b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Transforms defined!\n"
          ]
        }
      ],
      "source": [
        "train_transform = A.Compose([\n",
        "    A.RandomResizedCrop(height=224, width=224, scale=(0.8, 1.0)),\n",
        "    A.HorizontalFlip(p=0.5),\n",
        "    A.Rotate(limit=20, p=0.3),\n",
        "    A.OneOf([\n",
        "        A.GaussNoise(var_limit=(10.0, 50.0), p=1),\n",
        "        A.GaussianBlur(blur_limit=(3, 7), p=1),\n",
        "    ], p=0.3),\n",
        "    A.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1, p=0.3),\n",
        "    A.CLAHE(clip_limit=2.0, tile_grid_size=(8, 8), p=0.3),\n",
        "    A.CoarseDropout(max_holes=8, max_height=32, max_width=32, fill_value=0, p=0.3),\n",
        "    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "    ToTensorV2()\n",
        "])\n",
        "\n",
        "val_transform = A.Compose([\n",
        "    A.Resize(height=256, width=256),\n",
        "    A.CenterCrop(height=224, width=224),\n",
        "    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "    ToTensorV2()\n",
        "])\n",
        "\n",
        "print(\"‚úÖ Transforms defined!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a9ZLG6WFlgMJ",
        "outputId": "177fcc38-6067-4572-c7ae-f0d80875c23f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 50000 real images\n",
            "Found 50000 fake images\n",
            "Total samples: 10000\n",
            "Real: 5000\n",
            "Fake: 5000\n",
            "Train: 8000\n",
            "Validation: 2000\n"
          ]
        }
      ],
      "source": [
        "import glob\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "real_paths = glob.glob('/content/dataset/real_vs_fake/real-vs-fake/train/real/*.jpg')\n",
        "fake_paths = glob.glob('/content/dataset/real_vs_fake/real-vs-fake/train/fake/*.jpg')\n",
        "\n",
        "print(f\"Found {len(real_paths)} real images\")\n",
        "print(f\"Found {len(fake_paths)} fake images\")\n",
        "\n",
        "real_paths = real_paths[:5000]\n",
        "fake_paths = fake_paths[:5000]\n",
        "\n",
        "df = pd.DataFrame({\n",
        "    'path': real_paths + fake_paths,\n",
        "    'label': [0]*len(real_paths) + [1]*len(fake_paths)\n",
        "})\n",
        "\n",
        "df = df.sample(frac=1).reset_index(drop=True)\n",
        "\n",
        "print(f\"Total samples: {len(df)}\")\n",
        "print(f\"Real: {sum(df['label']==0)}\")\n",
        "print(f\"Fake: {sum(df['label']==1)}\")\n",
        "\n",
        "train_df, val_df = train_test_split(df, test_size=0.2, random_state=42, stratify=df['label'])\n",
        "\n",
        "print(f\"Train: {len(train_df)}\")\n",
        "print(f\"Validation: {len(val_df)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tc40oDoU8usA",
        "outputId": "50d0f914-c2a3-49da-9ba9-df9eee47112d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train batches: 250\n",
            "Validation batches: 63\n"
          ]
        }
      ],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_dataset = DeepfakeDataset(train_df, transform=train_transform)\n",
        "val_dataset = DeepfakeDataset(val_df, transform=val_transform, is_train=False)\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=32,\n",
        "    shuffle=True,\n",
        "    num_workers=2,\n",
        "    pin_memory=True\n",
        ")\n",
        "\n",
        "val_loader = DataLoader(\n",
        "    val_dataset,\n",
        "    batch_size=32,\n",
        "    shuffle=False,\n",
        "    num_workers=2,\n",
        "    pin_memory=True\n",
        ")\n",
        "\n",
        "print(f\"Train batches: {len(train_loader)}\")\n",
        "print(f\"Validation batches: {len(val_loader)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "56WO_Uwf9T8Q",
        "outputId": "eef1b36b-3296-42dd-b520-bdc3cbea6c66"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/efficientnet_b3_rwightman-b3899882.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet_b3_rwightman-b3899882.pth\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 47.2M/47.2M [00:00<00:00, 168MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Model initialized!\n",
            "Total parameters: 15,750,059\n"
          ]
        }
      ],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "model = DeepfakeModel().to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4, weight_decay=0.01)\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=10)\n",
        "\n",
        "print(\"‚úÖ Model initialized!\")\n",
        "print(f\"Total parameters: {sum(p.numel() for p in model.parameters()):,}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ze6COeu_9Z7F",
        "outputId": "f39da473-5aaa-40c8-dbf3-1a58d15d085d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==================================================\n",
            "EPOCH 1/5\n",
            "==================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 250/250 [01:20<00:00,  3.11it/s]\n",
            "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 63/63 [00:06<00:00,  9.14it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Train Loss: 0.5702, Train Acc: 69.35%\n",
            "Val Loss: 0.2654, Val Acc: 89.70%\n",
            "‚úÖ Saved best model with accuracy: 89.70%\n",
            "\n",
            "==================================================\n",
            "EPOCH 2/5\n",
            "==================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 250/250 [01:21<00:00,  3.07it/s]\n",
            "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 63/63 [00:06<00:00,  9.09it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Train Loss: 0.3864, Train Acc: 81.12%\n",
            "Val Loss: 0.1547, Val Acc: 94.05%\n",
            "‚úÖ Saved best model with accuracy: 94.05%\n",
            "\n",
            "==================================================\n",
            "EPOCH 3/5\n",
            "==================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 250/250 [01:24<00:00,  2.97it/s]\n",
            "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 63/63 [00:05<00:00, 10.83it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Train Loss: 0.3039, Train Acc: 84.69%\n",
            "Val Loss: 0.1089, Val Acc: 96.00%\n",
            "‚úÖ Saved best model with accuracy: 96.00%\n",
            "\n",
            "==================================================\n",
            "EPOCH 4/5\n",
            "==================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 250/250 [01:26<00:00,  2.88it/s]\n",
            "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 63/63 [00:06<00:00,  9.42it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Train Loss: 0.2624, Train Acc: 86.65%\n",
            "Val Loss: 0.0743, Val Acc: 97.45%\n",
            "‚úÖ Saved best model with accuracy: 97.45%\n",
            "\n",
            "==================================================\n",
            "EPOCH 5/5\n",
            "==================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 250/250 [01:27<00:00,  2.84it/s]\n",
            "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 63/63 [00:07<00:00,  8.86it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Train Loss: 0.2325, Train Acc: 88.61%\n",
            "Val Loss: 0.0728, Val Acc: 97.55%\n",
            "‚úÖ Saved best model with accuracy: 97.55%\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "num_epochs = 5\n",
        "best_val_acc = 0\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    print(f\"\\n{'='*50}\")\n",
        "    print(f\"EPOCH {epoch+1}/{num_epochs}\")\n",
        "    print(f\"{'='*50}\")\n",
        "\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "    train_correct = 0\n",
        "    train_total = 0\n",
        "\n",
        "    for images, labels in tqdm(train_loader, desc='Training'):\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "        _, predicted = outputs.max(1)\n",
        "        train_total += labels.size(0)\n",
        "        train_correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "    train_acc = 100. * train_correct / train_total\n",
        "\n",
        "    model.eval()\n",
        "    val_loss = 0\n",
        "    val_correct = 0\n",
        "    val_total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in tqdm(val_loader, desc='Validation'):\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            val_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            val_total += labels.size(0)\n",
        "            val_correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "    val_acc = 100. * val_correct / val_total\n",
        "    scheduler.step()\n",
        "\n",
        "    print(f\"\\nTrain Loss: {train_loss/len(train_loader):.4f}, Train Acc: {train_acc:.2f}%\")\n",
        "    print(f\"Val Loss: {val_loss/len(val_loader):.4f}, Val Acc: {val_acc:.2f}%\")\n",
        "\n",
        "    if val_acc > best_val_acc:\n",
        "        best_val_acc = val_acc\n",
        "        torch.save(model.state_dict(), '/content/best_model.pth')\n",
        "        print(f\"‚úÖ Saved best model with accuracy: {val_acc:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "ibM4YTKdAUMS",
        "outputId": "0bafc8a1-af4f-47fe-ad1d-b043e7c14b49"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Model saved to Google Drive: /content/drive/MyDrive/TruthLens/models/ensemble_model.pth\n",
            "‚úÖ Local copy saved\n"
          ]
        },
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_6d72c52b-cfa9-4357-aa5f-4d466a7923c1\", \"ensemble_model.pth\", 63588589)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "model_path = '/content/drive/MyDrive/TruthLens/models/ensemble_model.pth'\n",
        "torch.save({\n",
        "    'model_state_dict': model.state_dict(),\n",
        "    'model_config': 'efficientnet_b3_attention',\n",
        "    'val_accuracy': best_val_acc\n",
        "}, model_path)\n",
        "\n",
        "print(f\"‚úÖ Model saved to Google Drive: {model_path}\")\n",
        "\n",
        "torch.save(model.state_dict(), '/content/ensemble_model.pth')\n",
        "print(\"‚úÖ Local copy saved\")\n",
        "\n",
        "from google.colab import files\n",
        "files.download('/content/ensemble_model.pth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 807
        },
        "id": "HjxPsbYUA5Z2",
        "outputId": "6ce09a07-6009-41bf-c2a4-9eef29a35bcc"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 63/63 [00:06<00:00, 10.34it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üéØ Final Validation Accuracy: 97.55%\n",
            "\n",
            "üìä Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Real       0.99      0.96      0.98      1000\n",
            "        Fake       0.96      0.99      0.98      1000\n",
            "\n",
            "    accuracy                           0.98      2000\n",
            "   macro avg       0.98      0.98      0.98      2000\n",
            "weighted avg       0.98      0.98      0.98      2000\n",
            "\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 800x600 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "model.load_state_dict(torch.load('/content/best_model.pth'))\n",
        "model.eval()\n",
        "\n",
        "all_preds = []\n",
        "all_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in tqdm(val_loader):\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = outputs.max(1)\n",
        "\n",
        "        all_preds.extend(predicted.cpu().numpy())\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "accuracy = 100 * sum(np.array(all_preds) == np.array(all_labels)) / len(all_labels)\n",
        "print(f\"\\nüéØ Final Validation Accuracy: {accuracy:.2f}%\")\n",
        "\n",
        "print(\"\\nüìä Classification Report:\")\n",
        "print(classification_report(all_labels, all_preds, target_names=['Real', 'Fake']))\n",
        "\n",
        "cm = confusion_matrix(all_labels, all_preds)\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=['Real', 'Fake'],\n",
        "            yticklabels=['Real', 'Fake'])\n",
        "plt.title('Confusion Matrix')\n",
        "plt.ylabel('True Label')\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv (3.10.11)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
